<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Introduction to Ethics</title>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="author" content="Wouter Beek">
    <meta name="description" content="Introduction to Ethics">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="stylesheet" href="../../resource/reveal.js-3.8.0/css/reveal.css">
    <link rel="stylesheet" href="../../resource/reveal.js-3.8.0/css/theme/simple.css" id="theme">
    <link rel="stylesheet" href="../../resource/reveal.js-3.8.0/lib/css/default.css">
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? '../../resource/reveal.js-3.8.0/css/print/pdf.css' : '../../resource/reveal.js-3.8.0/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <section>
          <h1>Introduction to Ethics</h1>
        </section>

	      <section>
	        <h2>What is ethics?</h2>
	        <ul>
	          <li>Meta-ethics: Meaning of moral propositions</li>
	          <li>Theoretical ethics: Rational grounding of moral propositions</li>
	          <li>Practical ethics: Determine normative rules</li>
	          <li>Applied ethics: Societal norms</li>
	        </ul>
	      </section>

	      <section>
	        <h1>Prototypical moral argument</h1>
	        <ul>
	          <li>"You ought not to extort someone."</li>
	          <li>"Why not?"</li>
	          <li>Because…</li>
	          <ul>
	            <li>… extortion will hurt the person</li>
	            <li>… the person has feelings</li>
	            <li>… property rights have been agreed about in our society</li>
	          </ul>
	        </ul>
	      </section>

	      <section>
	        <h2>Meta-ethics:<br>Is/ought-problem</h2>
	      </section>

	      <section>
	        <h1>What is good?</h1>
	        <ul>
	          <li>Good is what the authorities who wield power over me say.</li>
	          <li>Good is that which has the highest utility.</li>
	          <li>Good is what God wants.</li>
	        </ul>
	      </section>

	      <section>
	        <h2>Meta-ethics:<br>Naturalistic fallacy</h2>
	        <blockquote>If <i>X</i> is good then the question whether <i>X</i> is good is meaningless.</blockquote>
        </section>

        <section>
          <h2>Theoretical ethics: Categorical imperative</h2>
          <blockquote>
            Act only according to a rule of which you can, at the same time, will that it should become a universal law without contradiction.
          </blockquote>
        </section>
        <section>
          <h2>Let's apply this…</h2>
          <blockquote>
            Act only according to that maxim whereby you can, at the same time, will that it should become a universal law without contradiction.
          </blockquote>
          <p class="fragment">Deception</p>
          <p class="fragment">Extortion</p>
          <p class="fragment">Assassination</p>
        </section>

        <section>
          <h2>Practical Ethics: To whom do these laws apply?</h2>
          <p class="fragment">Example: Killing an animal is wrong if an animal has (sufficient) sentience and/or sapience.</p>
          <div class="fragment">
            <hr>
            <p>Conditions for moral status:</p>
            <ul>
              <li><b>Sentience</b>: The capacity for phenomenal experience or qualia.</li>
              <li><b>Sapience</b>: A set of capabilities associated with higher intelligence (e.g., self-awareness, being a reason-responsive agent).</li>
            </ul>
          </div>
        </section>

        <section>
          <section>
            <h2>Principles regarding moral status attribution</h2>
            <ul>
              <li><b>Substrate Non-Discrimination</b></li>
              <li><b>Ontogeny Non-Discrimination</b></li>
              <li><b>Subjective Rate-of-Time</b></li>
            </ul>
          </section>
          <section>
            <h2>Principle of Substrate Non-Discrimination</h2>
            <blockquote>
              If two beings have the same functionality and the same conscious experience, and differ only in the substrate of their implementation, then they have the same moral status.
            </blockquote>
          </section>
          <section>
            <h2>Principle of Ontogeny Non-Discrimination</h2>
            <blockquote>
              If two beings have the same functionality and the same consciousness experience, and differ only in how they came into existence, then they have the same moral status.
            </blockquote>
          </section>
          <section>
            <h2>Principle of Subjective Rate-of-Time</h2>
            <p><b>Uploading</b>: A hypothetical future technology enables a human to be transferred from her original implementation in an organic brain onto a digital computer.</p>
            <p class="fragment">Suppose an upload could be sentient, then its subjective rate of time would be different from humans.</p>
            <blockquote class="fragment">
              In cases where the duration of an experience is of basic normative significance, it is experience's subjective duration that counts.
            </blockquote>
          </section>
        </section>

        <section>
          <h1>Ethical requirements for AI</h1>
        </section>

        <section>
          <h2>Why does AI have ethical requirements?</h2>
          <div class="fragment">
            <p>AI has ethical requirements through <i>inheritance</i>.</p>
            <p>Machines take on cognitive work with social dimensions from humans.</p>
          </div>
        </section>

        <section>
          <h2>How would you specifcy ethical requirements for AI?</h2>
        </section>

        <section>
          <h1>The Future of Life Institute</h1>
          <blockquote>
            [To] constitute a significant expansion of the field of AI itself, which up to now has focused largely on techniques that are neutral with respect to purpose.
            We recommend expanded research aimed at ensuring that increasingly capable AI systems are robust and beneficial: our AI systems must do what we want them to do.
          </blockquote>
        </section>

        <section>
          <h2>3 Laws of Robotics</h2>
          <ol>
            <li>A robot may not injure a human being or, through inaction, allow a human being to come to harm.</li>
            <li>A robot must obey the orders given it by human beings, except where such orders would conflict with Law 1.</li>
            <li>A robot must protect its own existence as long as such protection does not conflict with Laws 1 &amp; 2.</li>
          </ol>
        </section>

        <section>
          <h2>Static laws</h2>
          <blockquote>
            What if Archimedes of Syracuse had been able to create a long‐lasting AI with a fixed version of the moral code of Ancient Greece?
          </blockquote>
        </section>

        <section>
          <h2>AI behavior is specified <i>non-locally</i></h2>
          <p class="fragment">Deep Blue was not programmed in terms of individual chess moves.</p>
          <p class="fragment">Watson was not programmed in terms of individual trivia questions.</p>
          <p class="fragment">AIs are programmed in terms of the optimization of a non-local criterion (winning chess, answering trivia questions).</p>
          <p class="fragment">Good behavior as a non-local extrapolation of (future) consequences of generic behavior.</p>
        </section>

        <section>
          <h2>Ethical requirements specification for AI</h2>
          <p class="fragment">Require the AI to think like a human engineer that is concerned about ethics.</p>
          <p class="fragment">How do you build an AI which, when it executes, becomes more ethical than you?</p>
        </section>
      </div>
    </div>
    <script src="../../resource/reveal.js-3.8.0/lib/js/head.min.js"></script>
    <script src="../../resource/reveal.js-3.8.0/js/reveal.js"></script>
    <script>
			// More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'slide', // none/fade/slide/convex/concave/zoom
				// More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
          // Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
		      { src: '../../resource/reveal.js-3.8.0/js/classList.js', condition: function() { return !document.body.classList; } },
		      // Interpret Markdown in <section> elements
		      { src: '../../resource/reveal.js-3.8.0/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		      { src: '../../resource/reveal.js-3.8.0/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		      // Syntax highlight for <code> elements
		      { src: '../../resource/reveal.js-3.8.0/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
		      // Zoom in and out with Alt+click
		      { src: '../../resource/reveal.js-3.8.0/plugin/zoom-js/zoom.js', async: true },
		      // Speaker notes
		      { src: '../../resource/reveal.js-3.8.0/plugin/notes/notes.js', async: true },
		      // MathJax
		      { src: '../../resource/reveal.js-3.8.0/plugin/math/math.js', async: true }
        ]
      });
    </script>
  </body>
</html>
